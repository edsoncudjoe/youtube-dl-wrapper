#!/usr/bin/env python3

def pause(message="Press any key to continue"):
	print(message)
	input()

import os
import re
import sys
import subprocess
import sh
import urllib.parse
import glob


try:
	os.chdir("/home/user/_youtube")
except:
	print("Unable to os.chdir() to /home/user/_youtube, exiting.")
	pause()
	os._exit(1)


global downloaded_video_list
downloaded_video_list = set({})

global buffer_stdout
buffer_stdout = []

global buffer_stderr
buffer_stderr = []

global noplay
noplay = False


#from https://github.com/rg3/youtube-dl/
def extract_youtube_id(url):

	_VALID_URL = r"""^
                     (
                         (?:https?://)?                                       # http(s):// (optional)
                         (?:(?:(?:(?:\w+\.)?youtube(?:-nocookie)?\.com/|
                            tube\.majestyc\.net/|
                            youtube\.googleapis\.com/)                        # the various hostnames, with wildcard subdomains
                         (?:.*?\#/)?                                          # handle anchor (#/) redirect urls
                         (?:                                                  # the various things that can precede the ID:
                             (?:(?:v|embed|e)/)                               # v/ or embed/ or e/
                             |(?:                                             # or the v= param in all its forms
                                 (?:(?:watch|movie)(?:_popup)?(?:\.php)?)?    # preceding watch(_popup|.php) or nothing (like /?v=xxxx)
                                 (?:\?|\#!?)                                  # the params delimiter ? or # or #!
                                 (?:.*?&)?                                    # any other preceding param (like /?s=tuff&v=xxxx)
                                 v=
                             )
                         ))
                         |youtu\.be/                                          # just youtu.be/xxxx
                         )
                     )?                                                       # all until now is optional -> you can pass the naked ID
                     ([0-9A-Za-z_-]{11})                                      # here is it! the YouTube video ID
                     (?(1).+)?                                                # if we found the ID, everything can follow
                     $"""

	_NEXT_URL_RE = r'[\?&]next_url=([^&]+)'

	id = re.match(_VALID_URL, url, re.VERBOSE).groups()[-1]
	print(id)
	return id


def mplayer(file):
	cmd = sh.Command("mplayer")
	cmd(file)


def play(video_list):
	if noplay == True:
		return
	for file in video_list:
		pause("\nPress any key to play: " + str(file))
		play = "y"
		while play.lower() == "y":
			mplayer(file)
			print("Done playing.")
			play = input("\nEnter y to replay: ")


def output_buffer_stdout(input):
	stdout = open("/dev/stdout", "wb")
	buffer_stdout.append(input)
	try:
		stdout.write(input)
	except:
		stdout.write(bytes(input, 'UTF-8'))
	stdout.close()


def output_buffer_stderr(input):
	stderr = open("/dev/stderr", "wb")
	buffer_stderr.append(input)
	try:
		stderr.write(input)
	except:
		stderr.write(bytes(input, 'UTF-8'))
	stderr.close()


def get_clipboard():
	clipboard_text = subprocess.Popen(["xclip", "-o"], stdout=subprocess.PIPE).stdout.read()
	clipboard_text_utf8 = clipboard_text.decode("utf-8")
	print("clipboard_text_utf8:", clipboard_text_utf8)
	return clipboard_text_utf8


def extract_urls_from_text(intext):
	text = intext.split("\n")
	clean_text = filter(None, text)
	extracted_url_list = []
	for line in clean_text:
		for word in line.split(' '):
			urls = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\(\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', word)

			for url in urls:
				extracted_url_list.append(url)

	url_set = set(extracted_url_list)
	return list(url_set)


def get_clipboard_urls():
	clipboard_text = get_clipboard()
	urls = extract_urls_from_text(clipboard_text)
	return urls


def find_cached_file_by_id(item):
	print("trying to find", item)

	try:
		print("calling extract_youtube_id()")
		id = extract_youtube_id(item)
		print("id:", id)
	except:
		print("could not get video id, skipping.")
		return False

	try:
		matches = []
		pre_matches = glob.glob("*" + id + "*")
		for match in pre_matches:
			if match.endswith('.description'):
				continue
			if match.endswith('.json'):
				continue
			if match.endswith('.part'):
				continue
			matches.append(match)

		print("matches:", matches)
		if len(matches) == 0:
			print("No matches found. Skipping.")
			return False

	except:
		print("No matches found. Skipping.")
		return False

	print(matches)
	max = 0
	index_to_play = 0
	for index, match in enumerate(matches):
		size = os.stat(match).st_size
		if size > max:
			max = size
			index_to_play = index

	return matches[index_to_play]


def get_template_filename(url):
	cmd = sh.Command("/usr/bin/youtube-dl")
	output_file_template = "%(uploader)s__%(uploader_id)s__%(upload_date)s__%(title)s__%(extractor)s__%(id)s.%(ext)s"
	print("\nDownloading video IDs for:", url)
	for line in cmd("--simulate", "--get-filename", "--output", output_file_template, url, _piped=True):
		filename = line.strip()
	return filename


def get_default_filename(url):
	cmd = sh.Command("/usr/bin/youtube-dl")
	for line in cmd("--simulate", "--get-filename", url, _piped=True):
		filename = line.strip()
	print("get_default_filename():", filename)
	return filename


def download_default(url, destination):
	if check_lsof_for_duplicate_process(destination):
		print("Download in progress by another process, skipping.")
		return False

	if check_if_file_exists(destination):
		return True

	cmd = sh.Command("/usr/bin/youtube-dl")

	try:
		downloader = cmd("--verbose", "--continue", "--write-description", "--write-info-json", url, _out=output_buffer_stdout, _err=output_buffer_stderr, _out_bufsize=0)
		downloader.wait()
		exit_code = downloader.exit_code
		print("exit_code:", exit_code)
		if exit_code == 0:
			return True
		return False
	except:
		return False


def download_with_full_template(url, destination):
	if check_lsof_for_duplicate_process(destination):
		print("Download in progress by another process, skipping.")
		return False

	if check_if_file_exists(destination):
		return True

	output_file_template = "%(uploader)s__%(uploader_id)s__%(upload_date)s__%(title)s__%(extractor)s__%(id)s.%(ext)s"
	cmd = sh.Command("/usr/bin/youtube-dl")

	try:
		downloader = cmd("--verbose", "--continue", "--write-description", "--write-info-json", "--output", output_file_template, url, _out=output_buffer_stdout, _err=output_buffer_stderr, _out_bufsize=0)
		downloader.wait()
		exit_code = downloader.exit_code
		print("exit_code:", exit_code)
		if exit_code == 0:
			return True
		return False
	except:
		return False


def check_if_file_exists(destination):
	if os.path.isfile(destination):
		print("file:", destination, "exists. Skipping")
		downloaded_video_list.add(destination)
		return True

	return False


def check_lsof_for_duplicate_process(string):
	lsof_check = ""
	try:
		lsof_check = sh.grep(sh.lsof(), id)
	except:
		pass

	if len(lsof_check) > 0:
		print("lsof_check:", lsof_check)
		print("Found", id, "in lsof output, skipping.")
		return True

	return False


def process_url_list(url_list):

	#youtube-dl has it's own retry mechanism too
	max_tries = 10
	tries = 0

	print("url_list:", url_list)

	for item in url_list:

		if len(item) == 0:
			continue
		else:
			print("item:", item)

		#check for a video that has a ID in the url, and then play it, without hitting the network
		match = find_cached_file_by_id(item)

		if match:
			downloaded_video_list.add(match)
			continue

		try:
			try:
				filename = get_template_filename(item)
			except:
				continue
			destination = "/home/user/_youtube/" + filename

			while not os.path.isfile(destination) and tries <= max_tries:

				if tries == max_tries:
					print("---------LAST TRY---------")
				try:
					if download_with_full_template(item, destination):
						continue
				except sh.ErrorReturnCode_1:
					tries += 1

				except Exception as e:
					print("Exception:", e)
					print("Encountered unhanded exception. Exiting.")
					pause()
					os._exit(1)

			downloaded_video_list.add(destination)

		except:
			print("Problem getting template defined filename for: ", item, "Either the extractor does not support one of the template fields (like --get-id) for this video provider, or the video 404... attempting to download without --get-id")

			try:
				filename = get_default_filename(item)
			except:
				continue

			destination = "/home/user/_youtube/" + filename

			while not os.path.isfile(destination) and tries <= max_tries:

				if tries == max_tries:
					print("---------LAST TRY---------")
				try:
					if download_default(item, destination):
						continue
				except sh.ErrorReturnCode_1:
					tries += 1

				except Exception as e:
					print("Exception:", e)
					print("Encountered unhanded exception. Exiting.")
					pause()
					os._exit(1)

			downloaded_video_list.add(destination)

		buffer_stdout = []
		buffer_stderr = []
		tries = 0


if __name__ == '__main__':
	url_list = []

	if len(sys.argv) == 1:
		print("no args, checking clipboard for urls")
		url_list = get_clipboard_urls()

	else:
		for item in sys.argv[1:]:
			if item == 'noplay':
				noplay = True
			else:
				url_list.append(item)

	print("url_list:", url_list)
	process_url_list(url_list)
	print(" ")
	print(downloaded_video_list)
	play(downloaded_video_list)

	if noplay == False:
		#keep the terminal open if there was an error downloading
		pause("\nPress any key to exit")
